version: '3'
services:
  h01:
    restart: always
    build:
      dockerfile: Dockerfile
      context: ./namenode
    hostname: h01
    ports:
      - '9870:9870'
      - '8088:8088'
      - '9000:9000'
      - '50010:50010'
      - '8020:8020'
      - '8030:8030'
      - '9864:9864'

    container_name: h01
    stdin_open: true
    tty: true
    volumes:
      - ./hadoop_conf:/usr/local/hadoop/etc/hadoop
      - ./hbase_conf:/usr/local/hbase-2.2.2/conf
      - ./spark_conf:/usr/local/spark-2.4.0/conf
    depends_on:
      - h02
      - h03
      - h04
      - h05    
  h02:
    image: 'sunwenxiang/hadoop-hbase-spark:10.0'
    container_name: h02
    hostname: h02
    stdin_open: true
    tty: true
    volumes:
      - ./hadoop_conf:/usr/local/hadoop/etc/hadoop
      - ./hbase_conf:/usr/local/hbase-2.2.2/conf
      - ./spark_conf:/usr/local/spark-2.4.0/conf
  h03:
    image: 'sunwenxiang/hadoop-hbase-spark:10.0'
    container_name: h03
    hostname: h03
    stdin_open: true
    tty: true
    volumes:
      - ./hadoop_conf:/usr/local/hadoop/etc/hadoop
      - ./hbase_conf:/usr/local/hbase-2.2.2/conf
      - ./spark_conf:/usr/local/spark-2.4.0/conf
  h04:
    image: 'sunwenxiang/hadoop-hbase-spark:10.0'
    container_name: h04
    hostname: h04
    stdin_open: true
    tty: true
    volumes:
      - ./hadoop_conf:/usr/local/hadoop/etc/hadoop
      - ./hbase_conf:/usr/local/hbase-2.2.2/conf
      - ./spark_conf:/usr/local/spark-2.4.0/conf
  h05:
    image: 'sunwenxiang/hadoop-hbase-spark:10.0'
    container_name: h05
    hostname: h05
    stdin_open: true
    tty: true
    volumes:
      - ./hadoop_conf:/usr/local/hadoop/etc/hadoop
      - ./hbase_conf:/usr/local/hbase-2.2.2/conf
      - ./spark_conf:/usr/local/spark-2.4.0/conf
